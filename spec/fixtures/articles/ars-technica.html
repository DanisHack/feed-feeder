<!DOCTYPE html>
<!--[if lt IE 7]> <html lang="en-us" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>    <html lang="en-us" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>    <html lang="en-us" class="no-js ie8 lt-ie9"> <![endif]-->
<!--[if IE 9]>    <html lang="en-us" class="no-js ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html lang="en-us"> <!--<![endif]-->
<head>
<title>The 100 billion frames per second camera that can image light itself | Ars Technica</title>
    <script type="text/javascript">
    ars = {"ASSETS":"http:\/\/cdn.arstechnica.net\/wp-content\/themes\/arstechnica\/assets","HOME":"http:\/\/arstechnica.com","LOGIN_URL":"https:\/\/arstechnica.com\/services\/login-desktop.html?v=1","CIVIS":"\/civis","THEME":"dark","VIEW":"mobile","MOBILE":true,"PREMIER":false,"LOGGED":false,"ENV":"production","AD":{"kw":["science","culture"],"zone":"culture","queue":[]},"TOTAL":67424,"UNREAD":0,"RECENT":[636973,636537,636957,636899,636829,636873,636861,636797,630363,636245,636647,636763,636723,636697,636651,633041,636209,636379,636375,636331,618939,635909,636265,636321,636225],"LOGINS":true,"CROSS":false,"COMMENTS":false,"hide_year":false,"READY":[],"SHOW_ADS":true,"IMG_PROXY":"https:\/\/cdn.arstechnica.net\/i\/"};
  </script>

  <!--[if lte IE 8]><script type="text/javascript" src="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/js/modernizr/modernizr.js"></script><![endif]-->

      <link rel="stylesheet" type="text/css" media="all" href="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/css/ars.min.fe72647d2ca62d6da7f1d1f5a7bd90cc.css" />
      <link rel="alternate" type="application/rss+xml" href="http://feeds.arstechnica.com/arstechnica/index/" />
  <link rel="shortcut icon" href="https://cdn.arstechnica.net/favicon.ico" />
  <link rel="icon" type="image/x-icon" href="https://cdn.arstechnica.net/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/images/ars-ios-icon.png" />
  <link rel="icon" sizes="192x192" href="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/images/material-ars.png" />

  <meta name="application-name" content="Ars Technica"/>
  <meta name="msapplication-starturl" content="http://arstechnica.com/"/>
  <meta name="msapplication-tooltip" content="Ars Technica: Serving the technologist for 1.2 decades"/>
  <meta name="msapplication-task" content="name=News;action-uri=http://arstechnica.com/;icon-uri=https://cdn.arstechnica.net/favicon.ico"/>
  <meta name="msapplication-task" content="name=Features;action-uri=http://arstechnica.com/features/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-features.ico"/>
  <meta name="msapplication-task" content="name=OpenForum;action-uri=http://arstechnica.com/civis/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-forum.ico"/>
  <meta name="msapplication-task" content="name=Subscribe;action-uri=http://arstechnica.com/subscriptions/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-subscribe.ico"/>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="advertising" content="ask" />
  <meta property="fb:admins" content="592156917" />

  <meta name="format-detection" content="telephone=no" />
  <meta name="theme-color" content="#000000" />

      <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0" />

    <!-- cache hit 456:single/meta:364e652e9c3d58d724b184ef8a3b0c1a -->
<meta name='parsely-page' content='{"title":"The 100 billion frames per second camera that can image light itself","link":"http:\/\/arstechnica.com\/science\/2015\/01\/the-100-billion-frames-per-second-camera-that-can-image-light-itself\/","type":"post","author":"Chris Lee","post_id":592217,"pub_date":"2015-01-07T18:33:15Z","section":"Scientific Method","tags":["cameras","imaging","type: report"],"image_url":"http:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2015\/01\/Screen-Shot-2015-01-07-at-12.36.14-PM-150x150.png"}'>
<meta name='parsely-metadata' content='{"type":"report","title":"The 100 billion frames per second camera that can image light itself","post_id":592217,"lower_deck":"Slow motion action captures scattered photons as light moves through objects.","image_url":"http:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2015\/01\/Screen-Shot-2015-01-07-at-12.36.14-PM-150x150.png","listing_image_url":"http:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2015\/01\/Screen-Shot-2015-01-07-at-12.36.14-PM-300x150.png"}'>

<link rel="canonical" href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/" />

<link rel="shorturl" href="http://ars.to/1yAL6ne" />

<meta name="description" content="Slow motion action captures scattered photons as light moves through objects." />

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:url" content="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/">
<meta name="twitter:title" content="The 100 billion frames per second camera that can image light itself">
<meta name="twitter:description" content="Slow motion action captures scattered photons as light moves through objects.">
<meta name="twitter:site" content="@arstechnica">
<meta name="twitter:domain" content="arstechnica.com">
<meta name="twitter:image:src" content="http://cdn.arstechnica.net/wp-content/uploads/2015/01/Screen-Shot-2015-01-07-at-12.36.14-PM-640x451.png">
<meta name="twitter:image:width" content="640">
<meta name="twitter:image:height" content="451">

<meta name="twitter:creator" content="@exMamaku">

<meta property="og:url" content="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/" />
<meta property="og:title" content="The 100 billion frames per second camera that can image light itself" />
<meta property="og:image" content="http://cdn.arstechnica.net/wp-content/uploads/2015/01/Screen-Shot-2015-01-07-at-12.36.14-PM-640x451.png" />
<meta property="og:description" content="Slow motion action captures scattered photons as light moves through objects." />
<meta property="og:type" content="article" />
<meta property="og:site_name" content="Ars Technica" />
  <!-- cache hit 456:single/header:364e652e9c3d58d724b184ef8a3b0c1a -->
        
    <meta name="google-site-verification" content="HdFEloOqFNJZvQWa7SK2BRmWVt8aVnPuagqXZ-C2U5U" />
</head>
<body class="single single-post postid-592217 single-format-standard mobile-view dark blog-us">
  <div id="container">
    <header id="masthead">
              <aside id="ad-top">
          
<div id="topBanner320x50_frame"></div>
<script type="text/javascript">
ars.AD.queue.push(['topBanner', {sz: '320x50', kws: ["top"], collapse: true}]);
</script>

        </aside>

 
            <h1><a href="http://arstechnica.com"><em>Ars</em>Technica</a></h1>
            <div id="profile">
                    <a href="/civis/ucp.php?mode=register" rel="nofollow">Register</a>
        <a id="login" href="/civis/ucp.php?mode=login&return_to=http%3A%2F%2Farstechnica.com%2Fscience%2F2015%2F01%2Fthe-100-billion-frames-per-second-camera-that-can-image-light-itself%2F" rel="nofollow">Log in</a>
            </div>

      <nav id="primary">
              <ul>
        <li class="no-children"><a href="/civis/">Forums</a></li>
      </ul>

      </nav>
    </header>

    <div id="pushdown-wrap">
        </div>

    <section id="content" class="clearfix">
<!-- cache hit 456:home/toppost:f3fda06d4fb35e8aa360e369ff702613 -->
<h1 id="top-story">
  <em class="subheading">Live:</em> <a class="heading" href="http://live.arstechnica.com/robots-smart-factories-and-the-internet-of-stuff/">Robots, smart factories, and the Internet of&#8230;stuff</a>
&nbsp;
</h1>

<h1 id="archive-head" class="subheading thick-divide-bottom">
	<a href="http://arstechnica.com/science/">	<span class="archive-name">Scientific Method</span>
		<span class="divider"> / </span>
	<span class="archive-desc">Science &amp; Exploration</span>
		</a></h1>

<script type="text/javascript">
  ars.ARTICLE = {"url":"http:\/\/arstechnica.com\/science\/2015\/01\/the-100-billion-frames-per-second-camera-that-can-image-light-itself\/","short_url":"http:\/\/ars.to\/1yAL6ne","title":"The 100 billion frames per second camera that can image light itself","author":102179,"id":592217,"topic":1265821,"pages":1,"current_page":1,"superscroll":false,"promoted":[],"single_page":false,"comments":29,"fullwidth":false};
</script>

<article itemscope itemtype="http://schema.org/NewsArticle" class="standalone">
	<header>
		<h1 class="heading" itemprop="headline">The 100 billion frames per second camera that can image light itself</h1>
		<h2 class="standalone-deck" itemprop="description">Slow motion action captures scattered photons as light moves through objects.</h2>
		<div class="post-meta">
      
  <p class="byline" itemprop="author creator" itemscope itemtype="http://schema.org/Person">
  by     <a itemprop="url" href="http://arstechnica.com/author/laserboy/" rel="author"><span itemprop="name">Chris Lee</span></a>
  -    <span class="date" data-time="1420655595">Jan 7, 2015 6:33 pm UTC</span>
  </p>

			<div class="corner-info">
                                            <a title="27 posters participating, including story author." class="comment-count" href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/?comments=1"><span>29</span></a>

			</div>
		</div>
	</header>
	<section id="article-guts">
		<div itemprop="articleBody" class="article-content clearfix">
    
<figure class="intro-image image center full-width" style="width:640px">
      <img src="http://cdn.arstechnica.net/wp-content/uploads/2015/01/Screen-Shot-2015-01-07-at-12.36.14-PM-640x451.png" width="640" height="451">
  
    <figcaption class="caption">
	
			<div class="caption-credit">
							Gao et. al.				</div>
	  </figcaption>
  </figure>




    <p>High-speed cameras produce some of the most fascinating imagery in the world. They reveal hidden details and turn the everyday into the extraordinary. But these cameras, which generally top out at around 100,000 frames per second, have nothing on a camera reported last month in <a href="http://dx.doi.org/10.1038/nature14005"><em>Nature</em></a>. This beast can manage a massive <em>100 billion frames per second</em>.</p>
<p>If you want a high frame rate, you generally use stroboscopic imaging. In normal filming, the illumination is always on, and the camera shutter is operated as fast as possible. However, as the frame rate increases, the shutter time reduces and less light falls on the sensor. The result is a noisy image.</p>
<p>In the embedded video, you can see the difference between normal filming and stroboscopic imaging. Stroboscopic imaging builds up an image by pulsing the light source while the camera shutter remains open. Using it, you can capture single images from an event that repeats periodically. The temporal resolution is now given by the duration and timing of the light pulse. Light pulses can be less than a femtosecond (10<sup>-15</sup>s) in duration, while timing can be controlled with femtosecond precision. This allows stop-motion photography with frame rates of trillions per second.</p>
<p>The key point is that the filmed event must be predictably repeatable, which is why the stroboscopic part of the movie appears noisier: the fluid drop never expands exactly the same way.</p>
<figure class="video" style="width:100%"><iframe style="display:block" type="text/html" width="100%" height="450" src="http://www.youtube.com/embed/bRbHDtPbHe0?start=0&wmode=transparent" frameborder="0" allowfullscreen></iframe><figcaption class="caption"><div class="caption-text">Courtesy of Alexander Klein, <a title="Physics of Fluids" href="http://pof.tnw.utwente.nl">Physics of Fluids group</a>, University of Twente.</div> </figcaption></figure>
<p>There are many events for which high-speed imaging would be desirable, but the event does not repeat in a predictable manner, leaving stroboscopic imaging out. Think of gamma ray bursts, for example, or instabilities in confined plasmas (fusion reactors). The ability to capture details of these and other events would be a huge boon to scientists and engineers in many fields.</p>
<p>There is a compromise available in the form of a streak camera. A streak camera is a very fancy version of an ordinary digital camera. Instead of the whole sensor being used at the same time, only one column of pixels is exposed at a given time. As a result, a single image consists of one spatial dimension and a temporal dimension. That gets you speed, but if you want the full story, such a camera doesn't provide it—the second spatial dimension is lost (or must be regained by a scanning technique, which also requires a repeating event). In this case, the temporal dimension is limited by the speed of the electronics but still clocks in at a very respectable 10 picoseconds (10<sup>-12</sup>s).</p>
<h2>Reversing image compression</h2>
<p>However, we've realized in recent years that each pixel contains information about the entire image. By making some assumptions about the image and doing some calculations, it's possible to obtain a 2D image from a single pixel. This technique is called compressive sensing.</p>
<p>To play this game, you have to be able to represent the image by what is known as a sparse matrix. This is kind of complicated. The spatial information in an image can be represented by a set of basis functions (think cosine curves, for instance). The frequency of these cosines are evenly spaced over a range that is determined by both the size of the image and size of the pixel sensor (see <a href="http://arstechnica.com/science/2012/07/csi-image-enhancement/">here</a> for more detail). Each element of the matrix is the amplitude of a frequency component. This representation will generally not be sparse. Instead, every frequency component will be significant.</p>
<p>But imagine that you have an image that consists of a series of horizontal bars of varying width and spacing. Instead of using cosines, one might use a "bar" function with a set of widths and center positions. Our 2D image is now represented by just one column in the matrix, and most of those values will be zero. If you're lucky, this might be a sparse representation.</p>
<p>When you take this approach, the number of pixels that you use to obtain the image can be drastically reduced. The resolution or detail of the image is reclaimed through a set of calculations. Imagine that you want an image that consists of 256 by 256 pixels but you only have a 16 by 16 sensor. You take many images, and before the light falls on the sensor, you add a slight, well-defined distortion. At this stage, you choose a basis set that will represent each image sparsely—these are 16 by 16 matrices. After that, you expand the matrices to 256 by 256. The new matrices are not sparse, because if one element of the original matrix was non-zero, then a 16 by 16 block of the new matrix is non-zero.</p>
<p>A high-resolution image is created by creating an image that's just a guess at what you're looking at. You then calculate (including the distortion) the pattern it would create on the sensor. The results will be wrong, but you can use the difference between the two to refine the guess. Under the condition that the original and final matrix have the same degree of sparsity, the higher resolution should be a faithful reproduction of the object, but at a far higher resolution than your sensor originally provided.</p>
<h2>Bring compressive sensing to streak cameras</h2>
<p>By bringing these two technologies together, the researchers have obtained a camera that images entire scenes at 100 billion frames per second. So how does that work?</p>
<p>First, take an ordinary camera lens and use that to collect an image from an object. The collected light is then reflected off a mirror that is not flat. Indeed, this mirror is like a fun-house mirror, but the bends and bumps are on a much smaller scale, and the shape can be changed at will. After reflecting from the mirror, the light is sent to the streak camera, where one spatial dimension is thrown out and replaced with temporal information.</p>
<p>The streak camera is recording a distorted image, but the distortion is defined and can be used to retrieve the original 2D image using compressive sensing.</p>
<p>Normally, a <a href="http://arstechnica.com/science/2013/01/metamaterials-perform-image-compression-before-light-reaches-the-sensor/">single pixel sensor</a> is used in compressive sensing, and multiple images with different distortions are taken. In this case, though, only a single shot can be taken, so only a single distortion is applied. The image is then reconstructed by using the fact that each pixel in the column gets a slightly different distorted version of the image.</p>
<p>To demonstrate the effectiveness of the imaging technique, the researchers chose to image light in flight—nothing moves faster, right? A laser that emits light pulses with a duration of 7 picoseconds was fired at a mirror through dry ice. The dry ice scatters some of the light from the pulse as it travels. This scattered light was imaged by the system. If you were to look at such a situation with the naked eye—which I have done but don't necessarily recommend—you would simply see a green flash along the entire length of the dry ice column. However, with the researchers' fancy new camera, the image shows a <a href="http://www.nature.com/nature/journal/v516/n7529/fig_tab/nature14005_SV2.html">small pocket</a> (video) of light moving through the dry ice, reflecting off the mirror and continuing until it leaves the field of view of the camera. Even cooler, you can see some of the light leaking through the mirror.</p>
<p>Likewise, the researchers showed light <a href="http://www.nature.com/nature/journal/v516/n7529/fig_tab/nature14005_SV3.html">refracting</a> as it passed from air to resin, and they visualized two light pulses racing each other: one in air and one in resin (no guesses for which pulse won).</p>
<p><em>Nature</em>, 2014, DOI: <a href="http://dx.doi.org/10.1038/nature14005">10.1038/nature14005</a></p>
    		</div>
    <div class="article-expander">
      <p><a href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/">Expand full story</a></p>
    </div>
      	</section>

  <div id="article-footer-wrap">

	<section id="comments-area">
		
		<a name="comments-bar"></a>
		<div class="comments-bar">
      <a class="subheading comments-read-link" href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/?comments=1"><span class="text">Reader comments</span> <span class="comment-count"><span proptype>29</span></span></a>
		</div>
        <div id="comments-container"></div>
    <div id="comments-posting-container" class="thick-divide-bottom">
      <p id="reply">You must <a href="/civis/ucp.php?mode=login" class="vote_login">login or create an account</a> to comment.</p>
    </div>
    	</section>
	
  <aside class="thin-divide-bottom">
    </aside>

    <!-- cache hit 456:single/author:839a1f198ad36126a814b4c1fc3ff996 -->  	<section class="article-author clearfix-redux">
    				<a href="/author/laserboy"><img width="47" height="47" src="http://cdn.arstechnica.net/wp-content/uploads/authors/chris-lee2-sq.jpg"></a>
    		    
		<p><a href="/author/laserboy" class="author-name">Chris Lee</a>  / Chris writes for Ars Technica's science section. A physicist by day and science writer by night, he specializes in quantum physics and optics. He lives and works in Eindhoven, the Netherlands. </p>
				<a href="https://twitter.com/exMamaku" class="twitter-link">@exMamaku on Twitter</a>
			</section>
  
  
	<nav class="post-links thick-divide-top thin-divide-bottom clearfix-redux">
		<div class="subheading older"><a href="http://arstechnica.com/tech-policy/2015/01/lawmakers-facebook-rant-threatens-media-for-unauthorized-use-of-his-name/" rel="prev"><span class="arrow">&larr;</span> Older Story</a></div>
		<div class="subheading newer"><a href="http://arstechnica.com/tech-policy/2015/01/bitcoin-investor-who-renounced-us-citizenship-now-cant-get-back-in/" rel="next">Newer Story <span class="arrow">&rarr;</span></a></div>	
	</nav>

  
<div id="interstitial1x1_frame"></div>
<script type="text/javascript">
ars.AD.queue.push(['interstitial', {sz: '1x1', kws: ["interstitial"], collapse: true}]);
</script>


  </div>
</article>


		</section>
        <footer id="page-footer">
            
<div id="bottomBanner320x51_frame"></div>
<script type="text/javascript">
ars.AD.queue.push(['bottomBanner', {sz: '320x51', kws: ["bottom"], collapse: true}]);
</script>

      			<nav id="footer-nav">
				<div class="nav-section">
					<h2 class="subheading">Site Theme</h2>
					<ul>
                        <li><a href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/?mobile_theme=dark">Light on Dark</a></li>
            <li><a href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/?mobile_theme=light">Dark on Light</a></li>
            					</ul>
          <h2 class="subheading" id="full-site"><a href="http://arstechnica.com/science/2015/01/the-100-billion-frames-per-second-camera-that-can-image-light-itself/?view=grid">View Full Site</a></h2>
				</div>
			</nav>
	          <p style="text-align:center;margin-top:30px;margin-bottom:0"><a href="http://condenast.com"><img src="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/images/condenast-logo.png" width="131" height"19"></a></p>

			<div id="copyright-terms">
			© 2015 Condé Nast. All rights reserved<br>
			Use of this Site constitutes acceptance of our <a href="http://www.condenast.com/privacy-policy" target="_blank">User Agreement</a> (effective 1/2/14) and <a href="http://www.condenast.com/privacy-policy#privacypolicy" target="_blank">Privacy Policy</a> (effective 1/2/14), and <a href="/amendment-to-conde-nast-user-agreement-privacy-policy/">Ars Technica Addendum (effective 5/17/2012)</a><br>
			<a href="http://www.condenast.com/privacy-policy#privacypolicy-california" target="_blank">Your California Privacy Rights</a><br>
			The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.<br><br>
			<a href="http://www.condenast.com/privacy-policy#privacypolicy-optout" target="_blank">Ad Choices</a><img width="10" height="10" border="0" src="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/images/ad_choices_arrow.png">
			</div> 

		</footer>
	</div>

      <script type="text/javascript" src="//www.google.com/jsapi?autoload={'modules':[{'name':'search','version':'1','packages':[],'language':'en'}]}"></script>
  
		<script type="text/javascript" src="http://cdn.arstechnica.net/wp-content/themes/arstechnica/assets/js/ars.min.3e54b2f5ce4062493bd0a140e2b12387.js"></script>
	
<!-- what the christ -->

<script type="text/javascript" src="//www.googletagservices.com/tag/js/gpt.js"></script>
<script type="text/javascript" src="http://cdn.arstechnica.net/ads/js/cn.dart.bun.min.js"></script>

<script type="text/javascript">
  if ("CN" in window) {
    CN.site.init({
      code:  "ars",
      title: "Ars",
      name:  ars.MOBILE ? "ars.mobile" : "ars",
      env:   ars.ENV === "production" ? "PROD" : "DEV",
      debug: ars.ENV !== "production"
    });
    CN.dart.init({
      site: CN.site.name + '.dart',
      zone: ars.AD.zone,
      kws: ars.AD.kw,
      gptCallback: function(e) { ars.sda.ad_loaded(e); }
    });
    CN.dart.getCommon()["domDelay"]["defaultVal"] = 100;

    for (var i=0; i < ars.AD.queue.length; i++) {
      var ad = ars.AD.queue[i]
        , id = ad[0]
        , args = ad[1];
      if ($('#' + id + args.sz + "_frame").length)
        CN.dart.call(id, args);
    }

    ars.AD.queue = [];
  }
</script>

<script type="text/javascript">
CN.ad.polar.article = function (Handlebars,depth0,helpers,partials,data) {
  this.compilerInfo = [4,'>= 1.0.0'];
helpers = this.merge(helpers, Handlebars.helpers); data = data || {};
  var buffer = "", stack1, stack2, functionType="function", escapeExpression=this.escapeExpression, self=this;

function program1(depth0,data) {
  
  var buffer = "", stack1;
  buffer += "\n      <span style=\"width:50px; height:50px; overflow:hidden; display:inline-block; float:left; margin:2px 10px 5px 0\">\n        <img src=\""
    + escapeExpression(((stack1 = ((stack1 = depth0.image),stack1 == null || stack1 === false ? stack1 : stack1.href)),typeof stack1 === functionType ? stack1.apply(depth0) : stack1))
    + "\" style=\"float:none; margin:0; height:50px; width:auto;\" />\n      </span>\n    ";
  return buffer;
  }

  buffer += "<li>\n  <a href=\"";
  if (stack1 = helpers.link) { stack1 = stack1.call(depth0, {hash:{},data:data}); }
  else { stack1 = depth0.link; stack1 = typeof stack1 === functionType ? stack1.apply(depth0) : stack1; }
  buffer += escapeExpression(stack1)
    + "\">\n    <h2 style=\"color:#00A3D3;\">Sponsored by: <span style=\"text-transform:none;\">"
    + escapeExpression(((stack1 = ((stack1 = depth0.sponsor),stack1 == null || stack1 === false ? stack1 : stack1.name)),typeof stack1 === functionType ? stack1.apply(depth0) : stack1))
    + "</span></h2>\n    ";
  stack2 = helpers['if'].call(depth0, ((stack1 = depth0.image),stack1 == null || stack1 === false ? stack1 : stack1.href), {hash:{},inverse:self.noop,fn:self.program(1, program1, data),data:data});
  if(stack2 || stack2 === 0) { buffer += stack2; }
  buffer += "\n    <h1 class=\"heading\">";
  if (stack2 = helpers.title) { stack2 = stack2.call(depth0, {hash:{},data:data}); }
  else { stack2 = depth0.title; stack2 = typeof stack2 === functionType ? stack2.apply(depth0) : stack2; }
  buffer += escapeExpression(stack2)
    + "</h1>\n  </a>\n</li>";
  return buffer;
};
</script>

  
  <!-- cache hit 456:single/javascript-footer:f4f39d59fd4dc7b4bd9ac65860733a48 -->
        



      <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="http://condenast.112.2o7.net/b/ss/condenet-dev/1/H.15.1--NS/0" height="1" width="1" border="0" alt="" /></a></noscript>

  <!-- Google Analytics start -->
	<script type="text/javascript">
	var _gaq = _gaq || [];
  _gaq.push(
    ['_setAccount', 'UA-31997-1'],
    ['_setCustomVar', 1, 'view', "mobile"],
    ['_setCustomVar', 2, 'theme', "dark"],
    ['_setCustomVar', 3, 'logged_in', "false"],
    ['_setCustomVar', 4, 'show_comments', "false"],
    ['_setCustomVar', 5, 'is_premier', "false"],
    ['_trackPageview']
  );
	(function() {
	  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();
	</script>
  <!-- Google Analytics end -->

  <!-- Parse.ly start -->
	<script type="text/javascript">
  (function(d) {
    var site = "arstechnica.com",
    b = d.body,
    e = d.createElement("div");
    e.innerHTML = '<span id="parsely-cfg" data-parsely-site="'+site+'"></span>';
    e.id = "parsely-root";
    e.style.display = "none";
    b.appendChild(e);
  })(document);

  (function(s, p, d) {
    var h=d.location.protocol, i=p+"-"+s,
    e=d.getElementById(i), r=d.getElementById(p+"-root"),
    u=h==="https:"?"d1z2jf7jlzjs58.cloudfront.net"
      :"static."+p+".com";
    if (e) return;
    e = d.createElement(s); e.id = i; e.async = true;
    e.src = h+"//"+u+"/p.js"; r.appendChild(e);
  })("script", "parsely", document);
	</script>
  <!-- Parse.ly end -->

  
  
  
  </body>
</html>